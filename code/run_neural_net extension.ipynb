{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Neural Net Extension\n",
    "\n",
    "The script consists of image processing pipeline, original network and modified network.\n",
    "\n",
    "Output is learnt representation layers at given epoch, in form of numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26775,
     "status": "ok",
     "timestamp": 1620324025136,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "5gAhoxVIfd4M",
    "outputId": "a569bda5-00a7-49ff-81a4-ee274987c162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid, relu\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AatBYfsYequm"
   },
   "outputs": [],
   "source": [
    "# import the models for image transformation\n",
    "from tensorflow.keras.applications import (vgg16)\n",
    "\n",
    "vgg_model = vgg16.VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEP4rJz1fNWN"
   },
   "outputs": [],
   "source": [
    "#!pip install git+git://github.com/jaredwinick/img2vec-keras.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eewMxcTDfBWU"
   },
   "source": [
    "### Load Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_yh12KDmw8a"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/1016 Cognition Project/\"\n",
    "\n",
    "with open(path+'sem_items_animal_only.txt','r') as fid:\n",
    "    names_items = np.array([l.strip() for l in fid.readlines()])\n",
    "with open(path+'sem_relations_animal_only.txt','r') as fid:\n",
    "    names_relations = np.array([l.strip() for l in fid.readlines()])\n",
    "with open(path+'sem_attributes_animal_only.txt','r') as fid:\n",
    "    names_attributes = np.array([l.strip() for l in fid.readlines()])\n",
    "        \n",
    "nobj = len(names_items)\n",
    "nrel = len(names_relations)\n",
    "nattributes = len(names_attributes)\n",
    "#print('List of items:')\n",
    "#print(names_items)\n",
    "#print(\"List of relations:\")\n",
    "#print(names_relations)\n",
    "#print(\"List of attributes:\")\n",
    "#print(names_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1620324091189,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "i-JEznRyL8CX",
    "outputId": "aa46d4d6-9f64-48ee-db08-884aee5d8795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items:  77\n",
      "number of attributes:  239\n"
     ]
    }
   ],
   "source": [
    "print(\"number of items: \", nobj)\n",
    "print(\"number of attributes: \", nattributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1620324095273,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "x4rdhm2anHiJ",
    "outputId": "386c0482-0f5d-4ac3-91bd-6eef61c76b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input pattern:\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0]\n",
      "Example output pattern:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Which encodes...\n",
      "Item ['African elephant']\n",
      "Relation ['can']\n",
      "Attributes ['view']\n"
     ]
    }
   ],
   "source": [
    "D = np.loadtxt(path+'sem_data_animal_only.txt')\n",
    "input_pats = D[:,:nobj+nrel]\n",
    "input_pats = torch.tensor(input_pats,dtype=torch.float)\n",
    "output_pats = D[:,nobj+nrel:]\n",
    "output_pats = torch.tensor(output_pats,dtype=torch.float)\n",
    "N = input_pats.shape[0] # number of training patterns\n",
    "input_v = input_pats[0,:].numpy().astype('bool')\n",
    "output_v = output_pats[0,:].numpy().astype('bool')\n",
    "print('Example input pattern:')\n",
    "print(input_v.astype('int'))\n",
    "print('Example output pattern:')\n",
    "print(output_v.astype('int'))\n",
    "print(\"\")\n",
    "print(\"Which encodes...\")\n",
    "print('Item ',end='')\n",
    "print(names_items[input_v[:nobj]])\n",
    "print('Relation ',end='')\n",
    "print(names_relations[input_v[nobj:]])\n",
    "print('Attributes ',end='')\n",
    "print(names_attributes[output_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLV_HPFCui2_"
   },
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    input_v = input_pats[i,:].numpy().astype('bool')\n",
    "    output_v = output_pats[i,:].numpy().astype('bool')\n",
    "    #print(names_items[input_v[:nobj]],names_relations[input_v[nobj:]],names_attributes[output_v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueLyaSbyfd9A"
   },
   "source": [
    "### 2. Get Association Layer from Image, then concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBZo9i3Qfi4A"
   },
   "outputs": [],
   "source": [
    "names_items_processed = [name.lower() for name in names_items]\n",
    "names_items_processed = [name.replace(' ','_') for name in names_items_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VpAQHqXf0Ch"
   },
   "outputs": [],
   "source": [
    "from img2vec_keras import Img2Vec\n",
    "img2vec = Img2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx-j9KI7fmy9"
   },
   "outputs": [],
   "source": [
    "def get_vec(input_pat_vec):\n",
    "  # Binary input vector pattern, same as \"Example input pattern\" above\n",
    "  index = input_pat_vec.index(1)\n",
    "  item = names_items_processed[index] # name of the animal\n",
    "  image_path = path+'images/'+item+'.jpg'\n",
    "  image_vec = img2vec.get_vec(image_path)\n",
    "  return image_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVkcgpiqftYe"
   },
   "outputs": [],
   "source": [
    "vector_list = []\n",
    "\n",
    "for item_ind in range(len(input_pats)):\n",
    "  input_v = input_pats[item_ind,:].numpy().astype('bool')\n",
    "  input_pat_vec = list(input_v.astype('int'))\n",
    "  image_vec = get_vec(input_pat_vec)\n",
    "  vector_list.append(image_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBvypFeWf8LF"
   },
   "outputs": [],
   "source": [
    "# Compute similarity to each of the category group (by taking average of 4 pictures of each category group)\n",
    "\n",
    "category_names = ['amphibians', 'birds', 'fish', 'invertebrates', 'mammals', 'reptiles']\n",
    "\n",
    "cat_vectors = {}\n",
    "for cat_name in category_names:\n",
    "  temp = []\n",
    "  temp.append(img2vec.get_vec(path+'images/'+cat_name+'1.jpg'))\n",
    "  temp.append(img2vec.get_vec(path+'images/'+cat_name+'2.jpg'))\n",
    "  temp.append(img2vec.get_vec(path+'images/'+cat_name+'3.jpg'))\n",
    "  temp.append(img2vec.get_vec(path+'images/'+cat_name+'4.jpg'))\n",
    "  cat_vectors[cat_name] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7XLQjnngHR4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_category_similarity(item_index, cat_name):\n",
    "  cat_vec1 = cat_vectors[cat_name][0]\n",
    "  cat_vec2 = cat_vectors[cat_name][1]\n",
    "  cat_vec3 = cat_vectors[cat_name][2]\n",
    "  cat_vec4 = cat_vectors[cat_name][3]\n",
    "  item_vec = vector_list[item_index]\n",
    "  X = np.stack([item_vec, cat_vec1, cat_vec2, cat_vec3, cat_vec4])\n",
    "  Y = X\n",
    "  sim_matrix = cosine_similarity(X,Y)\n",
    "  sim_score = sim_matrix[0][1:].mean()\n",
    "  return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNxr1GPugLTi"
   },
   "outputs": [],
   "source": [
    "# Compute and store similarity score with each of 6 category\n",
    "sim_results = {}\n",
    "\n",
    "for cat_i in category_names:\n",
    "  temp_storage = []\n",
    "  for item_ind in range(len(vector_list)):\n",
    "    item_vec = vector_list[item_ind]\n",
    "    temp_storage.append(get_category_similarity(item_ind, cat_i))\n",
    "  sim_results[cat_i] = temp_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7LHx29AgfKi"
   },
   "outputs": [],
   "source": [
    "# Transform the category similarities and concatenate to original input\n",
    "\n",
    "association_raw = []\n",
    "for cat in sim_results.keys():\n",
    "  association_raw.append(sim_results[cat])\n",
    "\n",
    "association_raw = torch.tensor(association_raw)\n",
    "association = torch.transpose(association_raw, 0, 1)\n",
    "input_pats_new = torch.cat((input_pats, association), 1)\n",
    "\n",
    "#input_pats_new.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnQOaDztgT0B"
   },
   "source": [
    "### 3. Original NN and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YswgnTPWozL8"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, rep_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        # Input\n",
    "        #  rep_size : number of hidden units in \"Representation Layer\"\n",
    "        #  hidden_Size : number of hidden units in \"Hidden Layer\"\n",
    "        #\n",
    "        # TODO : YOUR CODE GOES HERE\n",
    "        self.fc_items_to_representation = nn.Linear(nobj, rep_size)\n",
    "        self.fc_representation_relation_to_hidden = nn.Linear(rep_size + nrel, hidden_size)\n",
    "        self.fc_hidden_to_attribute = nn.Linear(hidden_size, nattributes)\n",
    "        \n",
    "        #raise Exception('Replace with your code.')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defines forward pass for the network on input patterns x\n",
    "        #\n",
    "        # Input can take these two forms:\n",
    "        #\n",
    "        #   x: [nobj+nrel 1D Tensor], which is a single input pattern as a 1D tensor\n",
    "        #      (containing both object and relation 1-hot identifier) (batch size is B=1)\n",
    "        #   OR\n",
    "        #   x : [B x (nobj+nrel) Tensor], which is a batch of B input patterns (one for each row)\n",
    "        #\n",
    "        # Output\n",
    "        #   output [B x nattribute Tensor], which is the output pattern for each input pattern B on the Attribute Layer\n",
    "        #   hidden [B x hidden_size Tensor], which are activations in the Hidden Layer\n",
    "        #   rep [B x rep_size Tensor], which are the activations in the Representation LAyer\n",
    "        x = x.view(-1,nobj+nrel) # reshape as size [B x (nobj+nrel) Tensor] if B=1\n",
    "        x_item = x[:,:nobj] # input to Item Layer [B x nobj Tensor]\n",
    "        x_rel = x[:,nobj:] # input to Relation Layer [B x nrel Tensor]\n",
    "        # TODO : YOUR CODE GOES HERE\n",
    "        # ----\n",
    "        netinput_rep = self.fc_items_to_representation(x_item)\n",
    "        rep = relu(netinput_rep)\n",
    "        rep_rel = torch.cat((rep, x_rel),1) \n",
    "        netinput_hidden = self.fc_representation_relation_to_hidden(rep_rel)\n",
    "        hidden = relu(netinput_hidden)\n",
    "        netinput_attribute = self.fc_hidden_to_attribute(hidden)\n",
    "        output = sigmoid(netinput_attribute)\n",
    "        \n",
    "        #raise Exception('Replace with your code.')\n",
    "        # -----\n",
    "        return output, hidden, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNkRvRrao_cz"
   },
   "outputs": [],
   "source": [
    "def train(mynet,epoch_count,nepochs_additional=5000):\n",
    "    # Input\n",
    "    #  mynet : Net class object\n",
    "    #  epoch_count : (scalar) how many epochs have been completed so far\n",
    "    #  nepochs_additional : (scalar) how many more epochs we want to run\n",
    "    mynet.train()\n",
    "    for e in range(nepochs_additional): # for each epoch\n",
    "        error_epoch = 0.\n",
    "        perm = np.random.permutation(N)\n",
    "        for p in perm: # iterate through input patterns in random order\n",
    "            mynet.zero_grad() # reset gradient\n",
    "            output, hidden, rep = mynet(input_pats[p,:]) # forward pass\n",
    "            target = output_pats[p,:] \n",
    "            #print output and compare with target\n",
    "            #if e % 50 == 0:\n",
    "                #print(\"target: \",names_attributes[target.numpy().astype('bool')])\n",
    "                #print(\"output: \",names_attributes[np.where(output.detach().numpy()>0.5,1,0).astype('bool').flatten()])\n",
    "            loss = criterion(output, target) # compute loss\n",
    "            loss.backward() # compute gradient \n",
    "            optimizer.step() # update network parameters\n",
    "            error_epoch += loss.item()\n",
    "        error_epoch = error_epoch / float(N)        \n",
    "        if e % 50 == 0:\n",
    "            print('epoch ' + str(epoch_count+e) + ' loss ' + str(round(error_epoch,3)))\n",
    "    return epoch_count + nepochs_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1ILkr-FpGBU"
   },
   "outputs": [],
   "source": [
    "def get_rep(net):\n",
    "    # Extract the hidden activations on the Representation Layer for each item\n",
    "    # \n",
    "    # Input\n",
    "    #  net : Net class object\n",
    "    #\n",
    "    # Output\n",
    "    #  rep : [nitem x rep_size numpy array], where each row is an item\n",
    "    input_clean = torch.zeros(nobj,nobj+nrel)\n",
    "    for idx,name in enumerate(names_items):\n",
    "        input_clean[idx,idx] = 1. # 1-hot encoding of each object (while Relation Layer doesn't matter)\n",
    "    output, hidden, rep = mynet(input_clean)\n",
    "    return rep.detach().numpy()\n",
    "\n",
    "def plot_rep(rep1,rep2,rep3,names):\n",
    "    #  Compares Representation Layer activations of Items at three different times points in learning (rep1, rep2, rep3)\n",
    "    #  using bar graphs\n",
    "    # \n",
    "    #  Each rep1, rep2, rep3 is a [nitem x rep_size numpy array]\n",
    "    #  names : [nitem list] of item names\n",
    "    #\n",
    "    nepochs_list = [nepochs_phase1,nepochs_phase2,nepochs_phase3]\n",
    "    nrows = nobj\n",
    "    R = np.dstack((rep1,rep2,rep3))    \n",
    "    mx = R.max()\n",
    "    mn = R.min()\n",
    "    depth = R.shape[2]\n",
    "    count = 1\n",
    "    plt.figure(1,figsize=(4.2,360))\n",
    "    for i in range(nrows):\n",
    "        for d in range(R.shape[2]):\n",
    "            plt.subplot(nrows, depth, count)\n",
    "            rep = R[i,:,d]\n",
    "            plt.bar(range(rep.size),rep)\n",
    "            plt.ylim([mn,mx])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])        \n",
    "            if d==0:\n",
    "                plt.ylabel(names[i])\n",
    "            if i==0:\n",
    "                plt.title(\"epoch \" + str(nepochs_list[d]))\n",
    "            count += 1\n",
    "    plt.show()\n",
    "\n",
    "def plot_dendo(rep1,rep2,rep3,names):\n",
    "    #  Compares Representation Layer activations of Items at three different times points in learning (rep1, rep2, rep3)\n",
    "    #  using hierarchical clustering\n",
    "    # \n",
    "    #  Each rep1, rep2, rep3 is a [nitem x rep_size numpy array]\n",
    "    #  names : [nitem list] of item names\n",
    "    #\n",
    "    nepochs_list = [nepochs_phase1,nepochs_phase2,nepochs_phase3]\n",
    "    linked1 = linkage(rep1,'single')\n",
    "    linked2 = linkage(rep2,'single')\n",
    "    linked3 = linkage(rep3,'single')\n",
    "    mx = np.dstack((linked1[:,2],linked2[:,2],linked3[:,2])).max()+0.1    \n",
    "    plt.figure(2,figsize=(24, 20))\n",
    "    plt.subplot(3,1,1)    \n",
    "    dendrogram(linked1, labels=names, color_threshold=0)\n",
    "    plt.ylim([0,mx])\n",
    "    plt.title('Hierarchical clustering; ' + \"epoch \" + str(nepochs_list[0]))\n",
    "    plt.ylabel('Euclidean distance')\n",
    "    plt.subplot(3,1,2)\n",
    "    plt.title(\"epoch \" + str(nepochs_list[1]))\n",
    "    dendrogram(linked2, labels=names, color_threshold=0)\n",
    "    plt.ylim([0,mx])\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.title(\"epoch \" + str(nepochs_list[2]))\n",
    "    dendrogram(linked3, labels=names, color_threshold=0)\n",
    "    plt.ylim([0,mx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 457444,
     "status": "ok",
     "timestamp": 1620324715630,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "53hovH4VpUoF",
    "outputId": "66b0c8e6-f5e0-4289-f231-195eb828cc6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([239])) that is different to the input size (torch.Size([1, 239])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.25\n",
      "epoch 50 loss 0.017\n",
      "epoch 100 loss 0.015\n",
      "epoch 150 loss 0.013\n",
      "epoch 200 loss 0.013\n",
      "epoch 250 loss 0.012\n",
      "epoch 300 loss 0.012\n",
      "epoch 350 loss 0.012\n",
      "epoch 400 loss 0.012\n",
      "epoch 450 loss 0.012\n",
      "epoch 500 loss 0.012\n",
      "epoch 550 loss 0.012\n",
      "epoch 600 loss 0.012\n",
      "epoch 650 loss 0.012\n",
      "epoch 700 loss 0.011\n",
      "epoch 750 loss 0.011\n",
      "epoch 800 loss 0.011\n",
      "epoch 850 loss 0.011\n",
      "epoch 900 loss 0.011\n",
      "epoch 950 loss 0.011\n",
      "epoch 1000 loss 0.011\n",
      "epoch 1050 loss 0.011\n",
      "epoch 1100 loss 0.011\n",
      "epoch 1150 loss 0.011\n",
      "epoch 1200 loss 0.011\n",
      "epoch 1250 loss 0.011\n",
      "epoch 1300 loss 0.011\n",
      "epoch 1350 loss 0.011\n",
      "epoch 1400 loss 0.01\n",
      "epoch 1450 loss 0.01\n",
      "epoch 1500 loss 0.01\n",
      "epoch 1550 loss 0.01\n",
      "epoch 1600 loss 0.01\n",
      "epoch 1650 loss 0.01\n",
      "epoch 1700 loss 0.01\n",
      "epoch 1750 loss 0.01\n",
      "epoch 1800 loss 0.01\n",
      "epoch 1850 loss 0.01\n",
      "epoch 1900 loss 0.01\n",
      "epoch 1950 loss 0.01\n",
      "epoch 2000 loss 0.01\n",
      "epoch 2050 loss 0.01\n",
      "epoch 2100 loss 0.01\n",
      "epoch 2150 loss 0.01\n",
      "epoch 2200 loss 0.01\n",
      "epoch 2250 loss 0.009\n",
      "epoch 2300 loss 0.009\n",
      "epoch 2350 loss 0.009\n",
      "epoch 2400 loss 0.009\n",
      "epoch 2450 loss 0.009\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "mynet = Net(rep_size=8,hidden_size=15)\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "nepochs_phase1 = 500\n",
    "nepochs_phase2 = 1000\n",
    "nepochs_phase3 = 2500\n",
    "epoch_count = 0\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase1)\n",
    "rep1 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase2-nepochs_phase1)\n",
    "rep2 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase3-nepochs_phase2)\n",
    "rep3 = get_rep(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQq3_rgU-vSd"
   },
   "outputs": [],
   "source": [
    "#plot_rep(rep1,rep2,rep3,names_items)\n",
    "#plot_dendo(rep1,rep2,rep3,names_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1620324716031,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "SAd2C3-2M0fe",
    "outputId": "f33ac129-cee4-4e77-db50-3a2659a06f81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37yoEN_XSj71"
   },
   "outputs": [],
   "source": [
    "np.save(path+\"rep_array_animal_orig.npy\", rep3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPXsaEkkRaR"
   },
   "source": [
    "### 4. Modified NN and Training (Association Layer enters Hidden Layer directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1620325026443,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "1REcc0l2k5W0",
    "outputId": "de3dcbaa-f18a-454c-870f-4c5226812273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Objects: 77\n",
      "# Relations: 5\n",
      "# Attributes: 239\n",
      "# Associations: 6\n"
     ]
    }
   ],
   "source": [
    "nassociation = 6\n",
    "\n",
    "print('# Objects:', nobj)\n",
    "print('# Relations:', nrel)\n",
    "print('# Attributes:', nattributes)\n",
    "print('# Associations:', nassociation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dDRSxpYkTEv"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, rep_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        # Input\n",
    "        # rep_size : number of hidden units in \"Representation Layer\"\n",
    "        # hidden_Size : number of hidden units in \"Hidden Layer\"\n",
    "        self.rep_size = rep_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # function for linear transformation:\n",
    "        #   fc1: from item to representation\n",
    "        #   fc2: from representation+relation+association to hidden\n",
    "        #   fc3: from hidden layer to output \n",
    "        self.fc1 = nn.Linear(nobj, rep_size)\n",
    "        self.fc2 = nn.Linear(rep_size+nrel+nassociation, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, nattributes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defines forward pass for the network on input patterns x\n",
    "        #\n",
    "        # Input can take these two forms:\n",
    "        #\n",
    "        #   x: [nobj+nrel 1D Tensor], which is a single input pattern as a 1D tensor\n",
    "        #      (containing both object and relation 1-hot identifier) (batch size is B=1)\n",
    "        #   OR\n",
    "        #   x : [B x (nobj+nrel) Tensor], which is a batch of B input patterns (one for each row)\n",
    "        #\n",
    "        # Output\n",
    "        #   output [B x nattribute Tensor], which is the output pattern for each input pattern B on the Attribute Layer\n",
    "        #   hidden [B x hidden_size Tensor], which are activations in the Hidden Layer\n",
    "        #   rep [B x rep_size Tensor], which are the activations in the Representation LAyer\n",
    "        \n",
    "        x = x.view(-1,nobj+nrel+nassociation) # reshape as size [B x (nobj+nrel) Tensor] if B=1\n",
    "        x_item = x[:,:nobj] # input to Item Layer [B x nobj Tensor]\n",
    "        x_rel = x[:,nobj:nobj+nrel] # input to Relation Layer [B x nrel Tensor]\n",
    "        x_association = x[:,nobj+nrel:] # input to Association Layer [B x nassociation Tensor]\n",
    "        \n",
    "        rep = relu(self.fc1(x_item)) # representation layer tensor\n",
    "        rep_and_rel_and_association = torch.cat((rep.view(rep.size(0), -1), \n",
    "                                                 x_rel.view(x_rel.size(0), -1), \n",
    "                                                 x_association.view(x_association.size(0), -1)), dim=1)\n",
    "        hidden = relu(self.fc2(rep_and_rel_and_association))\n",
    "        output = sigmoid(self.fc3(hidden))\n",
    "    \n",
    "        return output, hidden, rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxZb2JCXluy6"
   },
   "outputs": [],
   "source": [
    "# Update train function: replace input_pats with input_pats_new\n",
    "\n",
    "def train(mynet,epoch_count,nepochs_additional=5000):\n",
    "    # Input\n",
    "    #  mynet : Net class object\n",
    "    #  epoch_count : (scalar) how many epochs have been completed so far\n",
    "    #  nepochs_additional : (scalar) how many more epochs we want to run\n",
    "    mynet.train()\n",
    "    for e in range(nepochs_additional): # for each epoch\n",
    "        error_epoch = 0.\n",
    "        perm = np.random.permutation(N)\n",
    "        for p in perm: # iterate through input patterns in random order\n",
    "            mynet.zero_grad() # reset gradient\n",
    "            output, hidden, rep = mynet(input_pats_new[p,:]) # forward pass\n",
    "            target = output_pats[p,:] \n",
    "            loss = criterion(output, target) # compute loss\n",
    "            loss.backward() # compute gradient \n",
    "            optimizer.step() # update network parameters\n",
    "            error_epoch += loss.item()\n",
    "        error_epoch = error_epoch / float(N)        \n",
    "        if e % 50 == 0:\n",
    "            print('epoch ' + str(epoch_count+e) + ' loss ' + str(round(error_epoch,3)))\n",
    "    return epoch_count + nepochs_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inCFdRdDpHuK"
   },
   "outputs": [],
   "source": [
    "# Change dimension of input for get_rep\n",
    "\n",
    "def get_rep(net):\n",
    "    '''\n",
    "    Extract the hidden activations on the Representation Layer for each item\n",
    "    Input\n",
    "       net : Net class object\n",
    "    # Output\n",
    "       rep : [nitem x rep_size numpy array], where each row is an item\n",
    "    '''\n",
    "    input_clean = torch.zeros(nobj,nobj+nrel+nassociation)\n",
    "    for idx,name in enumerate(names_items):\n",
    "        input_clean[idx,idx] = 1. # 1-hot encoding of each object (while Relation Layer doesn't matter)\n",
    "    output, hidden, rep = mynet(input_clean)\n",
    "    return rep.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478969,
     "status": "ok",
     "timestamp": 1620325515250,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "FuYRoP0ol9ZQ",
    "outputId": "7a45191e-2965-4ca4-a1f6-ac96b21d6cd6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([239])) that is different to the input size (torch.Size([1, 239])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.243\n",
      "epoch 50 loss 0.017\n",
      "epoch 100 loss 0.015\n",
      "epoch 150 loss 0.013\n",
      "epoch 200 loss 0.012\n",
      "epoch 250 loss 0.012\n",
      "epoch 300 loss 0.012\n",
      "epoch 350 loss 0.012\n",
      "epoch 400 loss 0.012\n",
      "epoch 450 loss 0.012\n",
      "epoch 500 loss 0.012\n",
      "epoch 550 loss 0.012\n",
      "epoch 600 loss 0.012\n",
      "epoch 650 loss 0.012\n",
      "epoch 700 loss 0.011\n",
      "epoch 750 loss 0.011\n",
      "epoch 800 loss 0.011\n",
      "epoch 850 loss 0.011\n",
      "epoch 900 loss 0.011\n",
      "epoch 950 loss 0.011\n",
      "epoch 1000 loss 0.011\n",
      "epoch 1050 loss 0.011\n",
      "epoch 1100 loss 0.011\n",
      "epoch 1150 loss 0.011\n",
      "epoch 1200 loss 0.011\n",
      "epoch 1250 loss 0.011\n",
      "epoch 1300 loss 0.01\n",
      "epoch 1350 loss 0.01\n",
      "epoch 1400 loss 0.01\n",
      "epoch 1450 loss 0.01\n",
      "epoch 1500 loss 0.01\n",
      "epoch 1550 loss 0.01\n",
      "epoch 1600 loss 0.01\n",
      "epoch 1650 loss 0.01\n",
      "epoch 1700 loss 0.01\n",
      "epoch 1750 loss 0.01\n",
      "epoch 1800 loss 0.01\n",
      "epoch 1850 loss 0.01\n",
      "epoch 1900 loss 0.01\n",
      "epoch 1950 loss 0.01\n",
      "epoch 2000 loss 0.009\n",
      "epoch 2050 loss 0.009\n",
      "epoch 2100 loss 0.009\n",
      "epoch 2150 loss 0.009\n",
      "epoch 2200 loss 0.009\n",
      "epoch 2250 loss 0.009\n",
      "epoch 2300 loss 0.009\n",
      "epoch 2350 loss 0.009\n",
      "epoch 2400 loss 0.009\n",
      "epoch 2450 loss 0.009\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "mynet = Net(rep_size=8,hidden_size=15)\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "nepochs_phase1 = 500\n",
    "nepochs_phase2 = 1000\n",
    "nepochs_phase3 = 2500\n",
    "epoch_count = 0\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase1)\n",
    "rep1 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase2-nepochs_phase1)\n",
    "rep2 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase3-nepochs_phase2)\n",
    "rep3 = get_rep(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpBh8kV6mWXT"
   },
   "outputs": [],
   "source": [
    "#plot_rep(rep1,rep2,rep3,names_items)\n",
    "#plot_dendo(rep1,rep2,rep3,names_items)\n",
    "\n",
    "np.save(path+\"rep_array_animal_association.npy\", rep3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73kqwoCm9MqP"
   },
   "source": [
    "### 5. Adjust image vector weights by *10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoHDhxhk5pb1"
   },
   "outputs": [],
   "source": [
    "association_raw = []\n",
    "for cat in sim_results.keys():\n",
    "  orig_vec = sim_results[cat]\n",
    "  weighted_vec = [float(10 * ele) for ele in orig_vec]\n",
    "  association_raw.append(weighted_vec)\n",
    "\n",
    "association_raw = torch.tensor(association_raw)\n",
    "association = torch.transpose(association_raw, 0, 1)\n",
    "input_pats_new = torch.cat((input_pats, association), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF_mVuLY-h6l"
   },
   "outputs": [],
   "source": [
    "# Update train function: replace input_pats with input_pats_new\n",
    "\n",
    "def train(mynet,epoch_count,nepochs_additional=5000):\n",
    "    # Input\n",
    "    #  mynet : Net class object\n",
    "    #  epoch_count : (scalar) how many epochs have been completed so far\n",
    "    #  nepochs_additional : (scalar) how many more epochs we want to run\n",
    "    mynet.train()\n",
    "    for e in range(nepochs_additional): # for each epoch\n",
    "        error_epoch = 0.\n",
    "        perm = np.random.permutation(N)\n",
    "        for p in perm: # iterate through input patterns in random order\n",
    "            mynet.zero_grad() # reset gradient\n",
    "            output, hidden, rep = mynet(input_pats_new[p,:]) # forward pass\n",
    "            target = output_pats[p,:] \n",
    "            loss = criterion(output, target) # compute loss\n",
    "            loss.backward() # compute gradient \n",
    "            optimizer.step() # update network parameters\n",
    "            error_epoch += loss.item()\n",
    "        error_epoch = error_epoch / float(N)        \n",
    "        if e % 50 == 0:\n",
    "            print('epoch ' + str(epoch_count+e) + ' loss ' + str(round(error_epoch,3)))\n",
    "    return epoch_count + nepochs_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476124,
     "status": "ok",
     "timestamp": 1620327757077,
     "user": {
      "displayName": "Jacqueline Yuwei Wang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgMT_sFU7mBNdoYW_ffBTeNRSM9IA27mo0TgfjVkQ=s64",
      "userId": "14242212518711821268"
     },
     "user_tz": 240
    },
    "id": "hJaMBIUQ9vPg",
    "outputId": "ce19261c-94ca-40eb-8ffe-3a140b4cceb8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([239])) that is different to the input size (torch.Size([1, 239])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.2\n",
      "epoch 50 loss 0.017\n",
      "epoch 100 loss 0.016\n",
      "epoch 150 loss 0.015\n",
      "epoch 200 loss 0.013\n",
      "epoch 250 loss 0.013\n",
      "epoch 300 loss 0.012\n",
      "epoch 350 loss 0.012\n",
      "epoch 400 loss 0.012\n",
      "epoch 450 loss 0.012\n",
      "epoch 500 loss 0.012\n",
      "epoch 550 loss 0.012\n",
      "epoch 600 loss 0.012\n",
      "epoch 650 loss 0.011\n",
      "epoch 700 loss 0.011\n",
      "epoch 750 loss 0.011\n",
      "epoch 800 loss 0.011\n",
      "epoch 850 loss 0.011\n",
      "epoch 900 loss 0.011\n",
      "epoch 950 loss 0.011\n",
      "epoch 1000 loss 0.011\n",
      "epoch 1050 loss 0.011\n",
      "epoch 1100 loss 0.011\n",
      "epoch 1150 loss 0.011\n",
      "epoch 1200 loss 0.011\n",
      "epoch 1250 loss 0.01\n",
      "epoch 1300 loss 0.01\n",
      "epoch 1350 loss 0.01\n",
      "epoch 1400 loss 0.01\n",
      "epoch 1450 loss 0.01\n",
      "epoch 1500 loss 0.01\n",
      "epoch 1550 loss 0.01\n",
      "epoch 1600 loss 0.01\n",
      "epoch 1650 loss 0.01\n",
      "epoch 1700 loss 0.009\n",
      "epoch 1750 loss 0.009\n",
      "epoch 1800 loss 0.009\n",
      "epoch 1850 loss 0.009\n",
      "epoch 1900 loss 0.009\n",
      "epoch 1950 loss 0.009\n",
      "epoch 2000 loss 0.009\n",
      "epoch 2050 loss 0.009\n",
      "epoch 2100 loss 0.009\n",
      "epoch 2150 loss 0.009\n",
      "epoch 2200 loss 0.009\n",
      "epoch 2250 loss 0.009\n",
      "epoch 2300 loss 0.009\n",
      "epoch 2350 loss 0.008\n",
      "epoch 2400 loss 0.008\n",
      "epoch 2450 loss 0.008\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "criterion = nn.MSELoss() # mean squared error loss function\n",
    "mynet = Net(rep_size=8,hidden_size=15)\n",
    "optimizer = torch.optim.SGD(mynet.parameters(), lr=learning_rate) # stochastic gradient descent\n",
    "\n",
    "nepochs_phase1 = 500\n",
    "nepochs_phase2 = 1000\n",
    "nepochs_phase3 = 2500\n",
    "epoch_count = 0\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase1)\n",
    "rep1 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase2-nepochs_phase1)\n",
    "rep2 = get_rep(mynet)\n",
    "epoch_count = train(mynet,epoch_count,nepochs_additional=nepochs_phase3-nepochs_phase2)\n",
    "rep3 = get_rep(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZK7KWwf-Rra"
   },
   "outputs": [],
   "source": [
    "np.save(path+\"rep_array_animal_weight10.npy\", rep3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65fFTCG6_Tyl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_neural_net extension.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
